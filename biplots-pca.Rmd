---
title: Work in progress
output:
    bookdown::pdf_document2:
        keep_tex: true
classoption: fleqn
---

# Pre-proccesing

```{r loadingdata, echo=FALSE}
knitr::opts_chunk$set(echo = FALSE, dpi = 300)
set.seed(842744)
library(dplyr, warn.conflicts = FALSE)

link <- "https://raw.githubusercontent.com/abarahonar/biplots-pca/master/owid-covid-data.csv" # nolint
data_original <- read.csv(url(link), header = TRUE)
```

The data used for this work comes from [Our World In Data's repositories](https://github.com/owid/covid-19-data/tree/master/public/data). The last entry on the data set corresponds to 10/08/2021.

## Cleaning

```{r deletingowidentries}
# Remove aggregations of data
# Those are denoted as an iso_code starting with OWID
ptn <- "^[^O][^W][^I][^D]*" # Will match anything that doesn't start with OWID
ndx <- grep(ptn, data_original$iso_code, perl = TRUE)
data <- data_original[ndx, ]
# To test it: unique(data.clean[c("iso_code")])
```

The original data set contains `r count(data_original)` entries with `r ncol(data_original)` variables. However, not all the data is needed. There are several entries that are not useful as they correspond to aggregations of data in terms of geolocalization. These entries marked as OWID consists of `r ceiling((1 - count(data)/count(data_original))*100)`% of the original data set. 

The variables in the data set can be used to represent two types of information: the evolution of the pandemic as a time series and metrics regarding the situation of the countries as a whole. The former correspond to dynamic data while the latter is static data.

### Countries data set
The variables used to represent the countries are:

```{r definitionofcountryvariables}
library(pander, warn.conflicts = FALSE)

country_variables <- c(
  "population",
  "population_density",
  "median_age",
  "gdp_per_capita",
  "cardiovasc_death_rate",
  "diabetes_prevalence",
  "hospital_beds_per_thousand",
  "life_expectancy",
  "human_development_index"
)

countries <- data[, which(names(data) %in% c("iso_code", country_variables))]
countries <- distinct(countries)

pander(country_variables)
```

The corresponding data set regarding the countries contains `r count(countries)` entries. However, not every country started reporting at the same time, in some situations there are noticeable differences in the starting reporting dates. A sample of the starting reporting dates can be seen in the Table \@ref(tab:reportingdates).

```{r reportingdates}
library(knitr, warn.conflicts = FALSE)

reporting_dates <- data[!duplicated(data$iso_code), ][c("iso_code", "date")]
rownames(reporting_dates) <- NULL

head_dates <- head(reporting_dates, n = 5)
tail_dates <- tail(reporting_dates, n = 5)

reporting_dates_t <- rbind(head_dates, tail_dates)
colnames(reporting_dates_t) <- c("ISO code", "Starting reporting date")

kable(reporting_dates_t, caption = "First and last 5 countries and their starting reporting dates. Alphabeticaly sorted. It can be seen in the fifth entry that the reporting date starts 1 year later in comparison to the majority of countries.") # nolint

fast_countries <- reporting_dates[reporting_dates$date < "2020-05-01", ]
countries <- countries[countries$iso_code %in% fast_countries$iso_code, ]
```

The date 05/01/2020 was selected as the threshold with which countries are removed from the data set. If they started reporting at a latter date, they are not considered. The remaining countries consists of `r count(countries)` entries.

```{r deletingnas}
countries <- na.omit(countries)
countries_with_names <- countries[, -1]
rownames(countries_with_names) <- countries[, 1]
countries <- countries_with_names
```

The next trimming consists of eliminating entries with one or more NA (***not assigned***) values. Afther this, the data set consists of `r count(countries)` entries. To see the behaviour of the data set, refer to the Figure \@ref(fig:lotboxplots).

```{r lotboxplots, fig.cap = "Boxplots of the different variables"}
library(ggplot2, warn.conflicts = FALSE)
library(reshape2, warn.conflicts = FALSE)

# The scales are way too big, we should normalize
countries_scaled <- scale(subset(countries, select = -c(population)))
ggplot(melt(countries_scaled), aes(Var2, value)) +
  geom_boxplot() +
  labs(x = "Variable's name", y = "Standardized values") +
  coord_flip()
```

### Time series data set

Regarding the time series, the entries related to countries that started to report significantly later than the others, and the measures that are before the aforementioned threshhold date are deleted. On top of that, variables that have a high percentage of NA values are not taken into consideration. A rundown of these variables can be seen in Table \@ref(tab:percentagesTable). It is worth mentioning that not all the variables shown in the aforementioned table are deleted, some of them are too importante to be discarded (like `total_test_per_thousand`)

```{r}
columns_to_delete <- c(
  "continent",
  "location",
  "excess_mortality_cumulative_absolute",
  "excess_mortality_cumulative",
  "excess_mortality",
  "excess_mortality_cumulative_per_million",
  "handwashing_facilities",
  "icu_patients",
  "icu_patients_per_million",
  "hosp_patients",
  "hosp_patients_per_million",
  "weekly_icu_admissions",
  "weekly_icu_admissions_per_million",
  "weekly_hosp_admissions",
  "weekly_hosp_admissions_per_million",
  "new_cases_smoothed",
  "new_deaths_smoothed",
  "new_cases_smoothed_per_million",
  "new_deaths_smoothed_per_million",
  "new_tests_smoothed",
  "new_tests_smoothed_per_thousand",
  "new_vaccinations_smoothed",
  "new_vaccinations_smoothed_per_million",
  "positive_rate",
  "total_cases",
  "new_cases",
  "total_deaths",
  "new_deaths",
  "new_tests",
  "total_tests",
  "total_vaccinations",
  "people_vaccinated",
  "people_fully_vaccinated",
  "total_boosters",
  "new_vaccinations",
  "aged_65_older",
  "tests_units",
  "aged_70_older"
)

unnecesary_variables <- c(
  columns_to_delete,
  country_variables
)

time_series <- data[, -which(names(data) %in% unnecesary_variables)]
time_series <- time_series[time_series$iso_code %in% rownames(countries), ]
time_series <- time_series[time_series$date >= "2020-05-01", ]
```

```{r percentagesTable}
percentages <- sapply(data,
                      function(x) ceiling(sum(is.na(x)) / count(data) * 100))
percentages <- as.data.frame(percentages)
percentages <- t(percentages)
percentages <- percentages[percentages > 60, ]
percentages <- as.data.frame(percentages)
percentages <- cbind(Row.Names = rownames(percentages), percentages)
rownames(percentages) <- NULL
colnames(percentages) <- c("variable", "percentage")
percentages$variable <- substr(percentages$variable,
                              1,
                              nchar(percentages$variable) - 2)
kable(percentages, caption="Variables with a percentage of NA values over 60\\%") # nolint
```

Another processing done to the time series corresponds to deleting relative variables to the day. This is done because its easier to interpret missing values in acumulative variables. The way it is interpreted is through the assumption that it takes the last known value. In the cases when there is no previous information, it is assumed to be 0.

```{r}
# Actually the next elimination can be only applied to total cases because they are the sum of every day cases. If we set previous values for an NA in columns like new_cases then we artificially increase total cases(?) because to determine total we sum up new once # nolint

# El unico problema de solamente tener los totales es que se pierden las correlaciones (ya que las variables siempre son crecientes) # nolint
totals <- subset(time_series, select = -c(
  new_tests_per_thousand,
  new_deaths_per_million,
  tests_per_case,
  new_cases_per_million
))

totals_modifies <- totals[0, ]

for (i in rownames(countries)) { # for each country
  country_subset <- totals[totals$iso_code == i, ]
  country_subset_mod <- country_subset
  # for each column name
  for (j in colnames(subset(country_subset, select = -c(date, iso_code)))) {
    col.values <- country_subset[[j]] #select one column
    for (k in seq_along(col.values)) {
      if (is.na(col.values[[k]])) { # if value = NA
        if (k == 1) { # if first element -> set = 0
          country_subset_mod[[j]][[k]] <- 0.0
        } else { # else set the last known one
          country_subset_mod[[j]][[k]] <- country_subset_mod[[j]][[k - 1]]
        }
      }
    }
  }
  totals_modifies <- rbind(totals_modifies, country_subset_mod)
}

time_series <- totals_modifies
```

#### Agreggation of temporal data

```{r}
aggregate_data <- function(countries, time_series, jump) {
  to_return <- time_series[0, ]
  for (i in rownames(countries)) {
    country_subset <- time_series[time_series$iso_code == i, ] # nolint
    j <- jump
    while (j <= nrow(country_subset)) {
      temp <- time_series[0, ]
      temp[1, ] <- NA
      temp[[1]][[1]] <- country_subset[[1]][[1]]
      temp[[2]][[1]] <- country_subset[[2]][[j]]
      for (k in colnames(subset(country_subset, select = -c(date, iso_code)))) {
        temp[[k]][[1]] <- country_subset[[k]][[j]]
      }
      to_return <- rbind(to_return, temp)
      j <- j + jump
    }
  }
  return(to_return)
}

time_series_weekly <- aggregate_data(countries, time_series, 7)
time_series_biweekly <- aggregate_data(countries, time_series, 14)
time_series_monthly <- aggregate_data(countries, time_series, 31)
```

Aggregation of data is done by temporal terms rather than geographical terms. This means that the time series is available with a daily, weekly, biweekly and monthly evolution, with `r nrow(time_series)`, `r nrow(time_series_weekly)`, `r nrow(time_series_biweekly)`, `r nrow(time_series_monthly)` entries respectively.

#### Plots of some variables in countries
```{r}
interesting_countires <- c(
  "RUS",
  "CHL",
  "CHN",
  "USA",
  "DEU",
  "FRA",
  "BRA",
  "TUR",
  "ITA",
  "KOR"
  ) #countries to plot

# Plot all totals
subset <- time_series[time_series$iso_code %in% interesting_countires, ]
p <- ggplot(data = subset,
            aes(x = date, y = total_cases_per_million,
            group = iso_code)) +
  geom_line(aes(color = iso_code)) +
  theme(axis.text.x = element_blank())
print(p)
# }
subset <- time_series[time_series$iso_code %in% interesting_countires, ]
p <- ggplot(data = subset,
            aes(x = date, y = total_deaths_per_million, group = iso_code)) +
  geom_line(aes(color = iso_code)) +
  theme(axis.text.x = element_blank())
print(p)

subset <- time_series[time_series$iso_code %in% interesting_countires, ]
p <- ggplot(data = subset,
            aes(x = date, y = reproduction_rate, group = iso_code)) +
  geom_line(aes(color = iso_code)) +
  theme(axis.text.x = element_blank())
print(p)

subset <- time_series[time_series$iso_code %in% interesting_countires, ]
p <- ggplot(data = subset,
            aes(x = date, y = total_tests_per_thousand, group = iso_code)) +
  geom_line(aes(color = iso_code)) +
  theme(axis.text.x = element_blank())
print(p)

subset <- time_series[time_series$iso_code %in% interesting_countires, ]
p <- ggplot(data = subset,
            aes(x = date,
                y = total_vaccinations_per_hundred,
                group = iso_code)) +
  geom_line(aes(color = iso_code)) +
  theme(axis.text.x = element_blank())
print(p)

subset <- time_series[time_series$iso_code %in% interesting_countires, ]
p <- ggplot(data = subset,
            aes(x = date,
                y = people_vaccinated_per_hundred,
                group = iso_code)) +
  geom_line(aes(color = iso_code)) +
  theme(axis.text.x = element_blank())
print(p)

subset <- time_series[time_series$iso_code %in% interesting_countires, ]
p <- ggplot(data = subset,
            aes(x = date,
                y = people_fully_vaccinated_per_hundred,
                group = iso_code)) +
  geom_line(aes(color = iso_code)) +
  theme(axis.text.x = element_blank())
print(p)

subset <- time_series[time_series$iso_code %in% interesting_countires, ]
p <- ggplot(data = subset,
            aes(x = date, y = total_boosters_per_hundred, group = iso_code)) +
  geom_line(aes(color = iso_code)) +
  theme(axis.text.x = element_blank())
print(p)

subset <- time_series[time_series$iso_code %in% interesting_countires, ]
p <- ggplot(data = subset,
            aes(x = date, y = stringency_index, group = iso_code)) +
  geom_line(aes(color = iso_code)) +
  theme(axis.text.x = element_blank())
print(p)

subset <- time_series[time_series$iso_code %in% interesting_countires, ]
p <- ggplot(data = subset,
            aes(x = date, y = total_cases_per_million, group = iso_code)) +
  geom_line(aes(color = iso_code)) +
  theme(axis.text.x = element_blank())
print(p)
```


## Hierarchical clustering

```{r dendogram, fig.cap="Hierarchical clustering"}
library("ggdendro", warn.conflicts = FALSE)

distance <- dist(countries_scaled)
countries_cluster <- hclust(distance)
# https://stackoverflow.com/questions/21474388/colorize-clusters-in-dendogram-with-ggplot2 # nolint
ggdendrogram(countries_cluster, rotate = TRUE, theme_dendro = FALSE)
```

## Scatter plot matrix

```{r scattermatrix, fig.cap="Scatter plot matrix"}
library(psych, warn.conflicts = FALSE)

pairs.panels(countries, pch = ".")
```

